{
  "metadata": {
    "name": "graphX-medline",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.SparkSession\n\nval spark\u003d SparkSession\n    .builder()\n    .appName(\"graphX\")\n    .getOrCreate()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import com.databricks.spark.xml._\n\nval rawXML \u003d spark.read.option(\"rowTag\", \"MedlineCitation\").xml(\"hdfs://namenode:8020/medline/*.xml\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rawXML.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import spark.implicits._\nval meshHeadlingList \u003d rawXML.select(\"MeshHeadingList.MeshHeading\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "meshHeadlingList.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val MeshHeadlingElems \u003d meshHeadlingList.withColumn(\"data\", explode($\"MeshHeading\")).select(\"data\")"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "MeshHeadlingElems.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val descriptorName \u003d MeshHeadlingElems.select(MeshHeadlingElems.col(\"data.DescriptorName\"))\ndescriptorName.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val parsedDF \u003d descriptorName.select(descriptorName.col(\"DescriptorName._MajorTopicYN\"),\n                                    descriptorName.col(\"DescriptorName._VALUE\").as(\"topic\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(parsedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val majorTopic \u003d parsedDF.filter(col(\"_MajorTopicYN\") \u003d\u003d\u003d \"Y\")"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(majorTopic)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDist \u003d majorTopic.groupBy(\"topic\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(topicDist.orderBy(desc(\"count\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topics \u003d majorTopic.select(\"topic\").rdd.map(el \u003d\u003e el.getString(0).split(\",\").toList)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val onlyTopics \u003d  topics.flatMap(mesh \u003d\u003e mesh).toDF(\"topic\")"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicPairs \u003d topics.flatMap(t \u003d\u003e {t.sorted.combinations(2)}).toDF(\"pairs\")\ntopicPairs.createOrReplaceTempView(\"topic_pairs\")\nval cooccurs \u003d spark.sql(\"\"\"\n    SELECT pairs, COUNT(*) cnt\n    FROM topic_pairs\n    GROUP BY pairs\"\"\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "cooccurs.createOrReplaceTempView(\"cooccurs\")\nspark.sql(\"\"\"\n    SELECT pairs, cnt\n    FROM cooccurs\n    ORDER BY cnt DESC\n    LIMIT 10\"\"\").collect().foreach(println)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import java.nio.charset.StandardCharsets\nimport java.security.MessageDigest\n\ndef hashID(str: String): Long \u003d {\n    val bytes \u003d MessageDigest.getInstance(\"MD5\").digest(str.getBytes(StandardCharsets.UTF_8))\n    (bytes(0) \u0026 0xFFL) |\n    ((bytes(1) \u0026 0xFFL) \u003c\u003c 8)  |\n    ((bytes(2) \u0026 0xFFL) \u003c\u003c 16) |\n    ((bytes(3) \u0026 0xFFL) \u003c\u003c 24) | \n    ((bytes(4) \u0026 0xFFL) \u003c\u003c 32) |\n    ((bytes(5) \u0026 0xFFL) \u003c\u003c 40) |\n    ((bytes(6) \u0026 0xFFL) \u003c\u003c 48) |\n    ((bytes(7) \u0026 0xFFL) \u003c\u003c 56)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.Row\n\nval vertices \u003d onlyTopics.map{ case Row(topic: String) \u003d\u003e (hashID(topic), topic) }.toDF(\"hash\", \"topic\")\nvertices.show(false)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.graphx._\n\nval edges \u003d cooccurs.map{ case Row(pairs: Seq[_], cnt: Long) \u003d\u003e\n    val ids \u003d pairs.map(_.toString).map(hashID).sorted\n    Edge(ids(0), ids(1), cnt)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val vertexRDD \u003d vertices.rdd.map{\n    case Row(hash: Long, topic: String) \u003d\u003e (hash, topic)\n}\nval topicGraph \u003d Graph(vertexRDD, edges.rdd)\ntopicGraph.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val connectedComponentGraph \u003d topicGraph.connectedComponents()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val componentDF \u003d connectedComponentGraph.vertices.toDF(\"vid\", \"cid\")\ncomponentDF.show(false)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "componentDF.groupBy(\"vid\").count().orderBy(\"count\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val componentCounts \u003d componentDF.groupBy(\"cid\").count()\ncomponentCounts.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(componentCounts.orderBy(desc(\"count\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val testGraphConnect \u003d componentDF.filter(col(\"cid\") \u003d\u003d\u003d \"-9080598076986622448\")\ntestGraphConnect.show"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinExp \u003d vertices.col(\"hash\") \u003d\u003d\u003d testGraphConnect.col(\"vid\")\nval joinWithVertexName \u003d testGraphConnect.join(vertices, joinExp).distinct()\n\njoinWithVertexName.show"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show( topicDist.filter($\"topic\".contains(\"Cell\")) )"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val degrees: VertexRDD[Int] \u003d topicGraph.degrees.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val testVertexDegree \u003d degrees.toDF(\"vertexID\", \"degree\")\n\ntestVertexDegree.where(col(\"vertexID\") \u003d\u003d\u003d \"-2024180124655511532\").show\nprintln(testVertexDegree.count)"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "testVertexDegree.describe(\"degree\").show"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicGraphVerteciesCount \u003d topicGraph.vertices.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopics \u003d topics.filter(x \u003d\u003e x.size \u003d\u003d 1)\nsingleTopics.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopicsDistinct \u003d singleTopics.flatMap(topic \u003d\u003e topic).distinct().toDS()\nsingleTopicsDistinct.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopicInPairs \u003d topicPairs.flatMap(_.getAs[Seq[String]](0))\nsingleTopicsDistinct.except(singleTopicInPairs).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "topicGraphVerteciesCount \u003d\u003d (testVertexDegree.select(\"degree\").count() + singleTopicsDistinct.except(singleTopicInPairs).count())"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val namesAndDegrees \u003d degrees.innerJoin(topicGraph.vertices) {\n    (topicId, degree, name) \u003d\u003e (name, degree.toInt)\n}.values.toDF(\"topic\", \"degree\")"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show( namesAndDegrees.orderBy(desc(\"degree\")) )"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val T \u003d majorTopic.count()\nsc.broadcast(T)"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDistRdd \u003d topicDist.map{\n    case Row(topic: String, count: Long) \u003d\u003e (hashID(topic), count)\n}.rdd"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDistGraph \u003d Graph(topicDistRdd, topicGraph.edges)"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def chiSq(YY: Long, YB: Long, YA: Long, T: Long): Double \u003d {\n    val NB \u003d T - YB\n    val NA \u003d T - YA\n    val YN \u003d YA - YY\n    val NY \u003d YB - YY\n    val NN \u003d T - NY - YN - YY\n    val inner \u003d math.abs(YY * NN - YN * NY) - T / 2.0\n    T * math.pow(inner, 2) / (YA * NA * YB * NB)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// https://spark.apache.org/docs/latest/api/scala/org/apache/spark/graphx/EdgeTriplet.html\nval topicDistGraphTriplet \u003d topicDistGraph.triplets.map(triplet \u003d\u003e \n    (triplet.srcAttr, triplet.srcId, triplet.attr, triplet.dstId, triplet.dstAttr))\n    .toDF(\"srcId\", \"srcAttr\",  \"attr\", \"dstId\", \"dstAttr\")\nz.show(topicDistGraphTriplet)"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val chiSquaredGraph \u003d topicDistGraph.mapTriplets(triplet \u003d\u003e {\n    chiSq(triplet.attr, triplet.srcAttr, triplet.dstAttr, T)\n})\nchiSquaredGraph.edges.map(x \u003d\u003e x.attr).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interesting \u003d chiSquaredGraph.subgraph(\n    triplet \u003d\u003e triplet.attr \u003e 19.5)\ninteresting.edges.count"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interestingComponentGraph \u003d interesting.connectedComponents()\nval icDF \u003d interestingComponentGraph.vertices.toDF(\"vid\", \"cid\")\nval icCountDF \u003d icDF.groupBy(\"cid\").count()\nicCountDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "icCountDF.orderBy(desc(\"count\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interestingDegrees \u003d interesting.degrees.cache()\ninterestingDegrees.map(_._2).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "interestingDegrees.innerJoin(topicGraph.vertices) {\n    (topicId, degree, name) \u003d\u003e (name, degree)\n}.values.toDF(\"topic\", \"degree\").orderBy(desc(\"degree\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val triCountGraph \u003d interesting.triangleCount()\ntriCountGraph.vertices.map(x \u003d\u003e x._2).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val maxTrisGraph \u003d interestingDegrees.mapValues(d \u003d\u003e d * (d-1) / 2.0)"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val clusterCoef \u003d triCountGraph.vertices.innerJoin(maxTrisGraph) { \n    (vertexId, triCount, maxTris) \u003d\u003e {if (maxTris \u003d\u003d 0) 0 else triCount / maxTris}\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "clusterCoef.map(_._2).sum() / interesting.vertices.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def mergeMaps(m1: Map[VertexId, Int], m2: Map[VertexId, Int]) : Map[VertexId, Int] \u003d {\n    def minThatExists(k: VertexId): Int \u003d {\n        math.min(m1.getOrElse(k, Int.MaxValue), m2.getOrElse(k, Int.MaxValue))\n    }\n    \n    (m1.keySet ++ m2.keySet).map(k \u003d\u003e (k, minThatExists(k))).toMap\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def update(id: VertexId, state: Map[VertexId, Int], msg: Map[VertexId, Int]) \u003d {\n    mergeMaps(state, msg)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def checkIncrement(a: Map[VertexId, Int], b: Map[VertexId, Int], bid: VertexId) \u003d {\n    val aplus \u003d a.map { case (v, d) \u003d\u003e v -\u003e (d+1) }\n    if(b !\u003d mergeMaps(aplus, b)) {\n        Iterator((bid, aplus))\n    } else {\n        Iterator.empty\n    }\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def iterate(e: EdgeTriplet[Map[VertexId, Int], _]) \u003d {\n    checkIncrement(e.srcAttr, e.dstAttr, e.dstId) ++\n    checkIncrement(e.dstAttr, e.srcAttr, e.srcId)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val fraction \u003d 0.02\nval replacement \u003d false\nval sample \u003d interesting.vertices.map(v \u003d\u003e v._1).sample(replacement, fraction, 1729L)\nval ids \u003d sample.collect().toSet"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mapGraph \u003d interesting.mapVertices((id, _) \u003d\u003e {\n    if (ids.contains(id)) {\n        Map(id -\u003e 0)\n    } else {\n        Map[VertexId, Int]()\n    }\n})"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val start \u003d Map[VertexId, Int]()\nval res \u003d mapGraph.pregel(start)(update, iterate, mergeMaps)"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val paths \u003d res.vertices.flatMap{ case(id, m) \u003d\u003e\n    m.map { case(k, v) \u003d\u003e\n        if (id \u003c k) {\n            (id, k, v)\n        } else {\n            (id, k, v)\n        }\n    }\n}.distinct()\npaths.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val pathDF \u003d paths.toDF(\"SrcVertexId\", \"DstVertexId\", \"PathLen\")"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(pathDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "pathDF.filter(col(\"PathLen\") \u003e 0).describe(\"PathLen\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(pathDF.groupBy(\"PathLen\").count())"
    }
  ]
}