{
  "metadata": {
    "name": "graphX-medline",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.SparkSession\n\nval spark\u003d SparkSession\n    .builder()\n    .appName(\"graphX\")\n    .getOrCreate()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import com.databricks.spark.xml._\n\nval rawXML \u003d spark.read.option(\"rowTag\", \"MedlineCitation\").xml(\"hdfs://namenode:8020/medline/*.xml\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rawXML.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import spark.implicits._\nval meshHeadlingList \u003d rawXML.select(\"MeshHeadingList.MeshHeading\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "meshHeadlingList.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val MeshHeadlingElems \u003d meshHeadlingList.withColumn(\"data\", explode($\"MeshHeading\")).select(\"data\")"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "MeshHeadlingElems.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val descriptorName \u003d MeshHeadlingElems.select(MeshHeadlingElems.col(\"data.DescriptorName\"))\ndescriptorName.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val parsedDF \u003d descriptorName.select(descriptorName.col(\"DescriptorName._MajorTopicYN\"),\n                                    descriptorName.col(\"DescriptorName._VALUE\").as(\"topic\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "parsedDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var majorTopic \u003d parsedDF.filter(col(\"_MajorTopicYN\") \u003d\u003d\u003d \"Y\")\nmajorTopic \u003d majorTopic.withColumn(\"topic\", regexp_replace(majorTopic(\"topic\"), \", \", \",\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "majorTopic.show"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDist \u003d majorTopic.groupBy(\"topic\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(topicDist.orderBy(desc(\"count\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topics \u003d majorTopic.select(\"topic\").rdd.map(el \u003d\u003e el.getString(0).split(\",\").toList)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val onlyTopics \u003d  topics.flatMap(mesh \u003d\u003e mesh).toDF(\"topic\")"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\n원소가 다르게 정렬되어 있는 리스트를 다른 리스트로 보기 때문에\n미리 정렬을 해줘야한다. 그 뒤 scala의 서브 리스트를 만드는 combinations 메소드를 사용한다.\n*/  \nval topicPairs \u003d topics.flatMap(t \u003d\u003e {t.sorted.combinations(2)}).toDF(\"pairs\") \ntopicPairs.createOrReplaceTempView(\"topic_pairs\")\nval cooccurs \u003d spark.sql(\"\"\"\n    SELECT pairs, COUNT(*) cnt\n    FROM topic_pairs\n    GROUP BY pairs\"\"\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "cooccurs.createOrReplaceTempView(\"cooccurs\")\nspark.sql(\"\"\"\n    SELECT pairs, cnt\n    FROM cooccurs\n    ORDER BY cnt DESC\n    LIMIT 20\"\"\").collect().foreach(println)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nGraphX는 두 개의 특화된 RDD를 사용해서 그래프를 생성한다\nVertextRDD[VD]는 RDD[(VertexId, VD)]의 구현\n    64 bit Long의 Key와 Value\nEdgeRDD[ED]는 RDD[(VertexID, ED)]의 구현\n    srcVertexId와 dstVertexId와 Value\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import java.nio.charset.StandardCharsets\nimport java.security.MessageDigest\n\ndef hashID(str: String): Long \u003d {\n    val bytes \u003d MessageDigest.getInstance(\"MD5\").digest(str.getBytes(StandardCharsets.UTF_8))\n    (bytes(0) \u0026 0xFFL) |\n    ((bytes(1) \u0026 0xFFL) \u003c\u003c 8)  |\n    ((bytes(2) \u0026 0xFFL) \u003c\u003c 16) |\n    ((bytes(3) \u0026 0xFFL) \u003c\u003c 24) | \n    ((bytes(4) \u0026 0xFFL) \u003c\u003c 32) |\n    ((bytes(5) \u0026 0xFFL) \u003c\u003c 40) |\n    ((bytes(6) \u0026 0xFFL) \u003c\u003c 48) |\n    ((bytes(7) \u0026 0xFFL) \u003c\u003c 56)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.Row\n\nval vertices \u003d onlyTopics.map{ case Row(topic: String) \u003d\u003e (hashID(topic), topic) }.toDF(\"hash\", \"topic\")\nvertices.show(false)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.graphx._\n\nval edges \u003d cooccurs.map{ case Row(pairs: Seq[_], cnt: Long) \u003d\u003e\n    val ids \u003d pairs.map(_.toString).map(hashID).sorted\n    Edge(ids(0), ids(1), cnt)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val vertexRDD \u003d vertices.rdd.map{\n    case Row(hash: Long, topic: String) \u003d\u003e (hash, topic)\n}\nval topicGraph \u003d Graph(vertexRDD, edges.rdd)\ntopicGraph.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nhttps://spark.apache.org/docs/latest/img/property_graph.png\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val connectedComponentGraph \u003d topicGraph.connectedComponents()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nhttps://drek4537l1klr.cloudfront.net/bonaci/Figures/09fig03.jpg\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val componentDF \u003d connectedComponentGraph.vertices.toDF(\"vid\", \"cid\")\ncomponentDF.show(false)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val componentCounts \u003d componentDF.groupBy(\"cid\").count()\ncomponentCounts.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "componentCounts.orderBy(desc(\"count\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val testGraphConnect \u003d componentDF.filter(col(\"cid\") \u003d\u003d\u003d \"-5431966423110682938\")\ntestGraphConnect.show"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinExp \u003d vertices.col(\"hash\") \u003d\u003d\u003d testGraphConnect.col(\"vid\")\nval joinWithVertexName \u003d testGraphConnect.join(vertices, joinExp).distinct()\n\njoinWithVertexName.orderBy(col(\"topic\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "topicDist.filter($\"topic\".contains(\"Diet\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "topicDist.filter($\"topic\".contains(\"Demography\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val degrees: VertexRDD[Int] \u003d topicGraph.degrees.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val testVertexDegree \u003d degrees.toDF(\"vertexID\", \"degree\")\n\ntestVertexDegree.where(col(\"vertexID\") \u003d\u003d\u003d \"-5431966423110682938\").show\nprintln(testVertexDegree.count)"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "testVertexDegree.describe(\"degree\").show"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicGraphVerteciesCount \u003d topicGraph.vertices.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopics \u003d topics.filter(x \u003d\u003e x.size \u003d\u003d 1)\nsingleTopics.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopicsDistinct \u003d singleTopics.flatMap(topic \u003d\u003e topic).distinct().toDS()\nsingleTopicsDistinct.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val singleTopicInPairs \u003d topicPairs.flatMap(_.getAs[Seq[String]](0))\nsingleTopicsDistinct.except(singleTopicInPairs).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "topicGraphVerteciesCount \u003d\u003d (testVertexDegree.select(\"degree\").count() + singleTopicsDistinct.except(singleTopicInPairs).count())"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val namesAndDegrees \u003d degrees.innerJoin(topicGraph.vertices) {\n    (topicId, degree, name) \u003d\u003e (name, degree.toInt)\n}.values.toDF(\"topic\", \"degree\")"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "namesAndDegrees.orderBy(desc(\"degree\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val T \u003d majorTopic.count() // 전체 문서의 수\nsc.broadcast(T)"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDistRdd \u003d topicDist.map{\n    case Row(topic: String, count: Long) \u003d\u003e (hashID(topic), count)\n}.rdd"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val topicDistGraph \u003d Graph(topicDistRdd, topicGraph.edges)"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def chiSq(YY: Long, YB: Long, YA: Long, T: Long): Double \u003d {\n    val NB \u003d T - YB // B가 나오지 않음\n    val NA \u003d T - YA // A가 나오지 않음\n    val YN \u003d YA - YY // A 나오고 B 나오지 않음\n    val NY \u003d YB - YY // A 나오지 않고 B 나옴\n    val NN \u003d T - NY - YN - YY // A 와 B 모두 나오지 않음\n    val inner \u003d math.abs(YY * NN - YN * NY) - T / 2.0 // 카이제곱 통계량 1\n    T * math.pow(inner, 2) / (YA * NA * YB * NB) // 카이제곱 통계량 2\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// https://spark.apache.org/docs/latest/api/scala/org/apache/spark/graphx/EdgeTriplet.html\nval topicDistGraphTriplet \u003d topicDistGraph.triplets.map(triplet \u003d\u003e \n    (triplet.srcAttr, triplet.srcId, triplet.attr, triplet.dstId, triplet.dstAttr))\n    .toDF(\"srcId\", \"srcAttr\",  \"attr\", \"dstId\", \"dstAttr\")\ntopicDistGraphTriplet.show"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val chiSquaredGraph \u003d topicDistGraph.mapTriplets(triplet \u003d\u003e {\n    chiSq(triplet.attr, triplet.srcAttr, triplet.dstAttr, T)\n})\nchiSquaredGraph.edges.map(x \u003d\u003e x.attr).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interesting \u003d chiSquaredGraph.subgraph(\n    triplet \u003d\u003e triplet.attr \u003e 19.5)\ninteresting.edges.count  // 0 - 2333, 19.5 2326"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interestingComponentGraph \u003d interesting.connectedComponents()\nval icDF \u003d interestingComponentGraph.vertices.toDF(\"vid\", \"cid\")\nval icCountDF \u003d icDF.groupBy(\"cid\").count()\nicCountDF.count() // Edge의 수 "
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "icCountDF.orderBy(desc(\"count\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val interestingDegrees \u003d interesting.degrees.cache()\ninterestingDegrees.map(_._2).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "interestingDegrees.innerJoin(topicGraph.vertices) {\n    (topicId, degree, name) \u003d\u003e (name, degree)\n}.values.toDF(\"topic\", \"degree\").orderBy(desc(\"degree\")).show"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\n    Collective Dynamics of \u0027Small-world Networks\u0027\n    완전 그래프 - 그래프에서 서로 다른 모든 Vertex가 반드시 연결되어 있는 그래프\n    \n    어떤 그래프가 완전 부분그래프(Clique)를 가지는 것을 찾는것이 NP-Complete Prob\n    간접적으로 Triangle Count( Vertex 세개로 이루어진 완전 그래프)를 이용한다.\n    Triangle Count를 사용하는 지역 군집 계수 ( Local Clustering Coefficient )\n    식 \u003d 실제 존재하는 트라이 앵글 수  /  만들 수 있는 전체 트라이앵글 수\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val triCountGraph \u003d interesting.triangleCount()\ntriCountGraph.vertices.map(x \u003d\u003e x._2).stats()"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val maxTrisGraph \u003d interestingDegrees.mapValues(d \u003d\u003e d * (d-1) / 2.0)"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val clusterCoef \u003d triCountGraph.vertices.innerJoin(maxTrisGraph) { \n    (vertexId, triCount, maxTris) \u003d\u003e {if (maxTris \u003d\u003d 0) 0 else triCount / maxTris}\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "clusterCoef.map(_._2).sum() / interesting.vertices.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nVertex간 경로(Path)의 길이를 구하기\n\n    for\n        \u003d\u003e 각 꼭짓점과 그 꼭짓점 까지의 거리의 목록을 만든다.\n        \u003d\u003e 아웃 노드들에 그들이 보유한 목록을 질의한다.\n        \u003d\u003e 자신에게 없는 꼭짓점 까지의 거리를 추가 갱신한다.\n    end 더이상 추가할 수 없을 때 까지 반복한다.\n\nPregel 은 Computation(계산)과 Communication(통신) 두 단계로 나누어 병렬 프로그래밍\n\n    Computation : 각 Vertex에서 내부 상태를 검사해 다른 Vertex에 \u0027Message\u0027를 보낼 것을 정한다.\n    Communication : 이전 통신 단계의 결과로 나온 메시지를 적당한 Vertex로 보낼 수 있도록 경로를 지정\n    \nPregel API 를 사용할 때 구현해야할 함수\n    1. 각 Vertex의 상태를 추적하는 함수 ( 어떤 상태를 추적할 건지 )\n    2. 이웃하는 Vertex의 각 쌍을 평가한 후, 다음 단계에 보낼 함수를 정하는 함수\n    3. 받은 메시지 들을 통합해서 자신(Vertex)의 상태를 업데이트 함수\n\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\n    평균 경로 길이 문제 \n    각 Vertex의 상태 : 알려진 다른 ( VertexId, 거리 ) -\u003e Map[VertexId, Int] ( 룩업 테이블)\n    각 Vertex에 전달할 메시지 : ( VertexId, 거리 ) -\u003e Map[VertexId, Int] ( 룩업 테이블 )\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def mergeMaps(m1: Map[VertexId, Int], m2: Map[VertexId, Int]) : Map[VertexId, Int] \u003d {\n    def minThatExists(k: VertexId): Int \u003d {\n        math.min(m1.getOrElse(k, Int.MaxValue), m2.getOrElse(k, Int.MaxValue))\n    }\n    \n    (m1.keySet ++ m2.keySet).map(k \u003d\u003e (k, minThatExists(k))).toMap // 동시에 나타는 VertexId에 대해서 더 작은 값을 보관한다\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def update(id: VertexId, state: Map[VertexId, Int], msg: Map[VertexId, Int]) \u003d {\n    mergeMaps(state, msg)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def checkIncrement(a: Map[VertexId, Int], b: Map[VertexId, Int], bid: VertexId) \u003d {\n    val aplus \u003d a.map { case (v, d) \u003d\u003e v -\u003e (d+1) } // 거리 1 증가\n    if(b !\u003d mergeMaps(aplus, b)) {\n        Iterator((bid, aplus)) // 이웃 Vertex의 상태와 다르다면 이웃 Vertex에 결과를 보낼 메시지 생성\n    } else {\n        Iterator.empty\n    }\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def iterate(e: EdgeTriplet[Map[VertexId, Int], _]) \u003d {\n    checkIncrement(e.srcAttr, e.dstAttr, e.dstId) ++\n    checkIncrement(e.dstAttr, e.srcAttr, e.srcId)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val fraction \u003d 0.02\nval replacement \u003d false\nval sample \u003d interesting.vertices.map(v \u003d\u003e v._1).sample(replacement, fraction, 1729L)\nval ids \u003d sample.collect().toSet"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mapGraph \u003d interesting.mapVertices((id, _) \u003d\u003e {\n    if (ids.contains(id)) {\n        Map(id -\u003e 0)\n    } else {\n        Map[VertexId, Int]()\n    }\n})"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val start \u003d Map[VertexId, Int]()\nval res \u003d mapGraph.pregel(start)(update, iterate, mergeMaps)"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val paths \u003d res.vertices.flatMap{ case(id, m) \u003d\u003e // VertexId, ( VertexId, Int )\n    m.map { case(k, v) \u003d\u003e // ( VertexId, Int )\n        if (id \u003c k) {\n            (id, k, v)\n        } else {\n            (id, k, v)\n        }\n    }\n}.distinct()\npaths.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val pathDF \u003d paths.toDF(\"SrcVertexId\", \"DstVertexId\", \"PathLen\")"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "pathDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "pathDF.filter(col(\"PathLen\") \u003e 0).describe(\"PathLen\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "pathDF.groupBy(\"PathLen\").count().show"
    }
  ]
}